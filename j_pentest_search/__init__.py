#!/usr/bin/env python
# encoding: utf8

import os
import sys
import requests
import urllib
from bs4 import BeautifulSoup

import j_pentest_utils

def baidu_search( keyword, page ):
    """
    baidu search, return urls as a set
    """
    urls = set()
    for page in range( 0, 10*page, 10 ):
        url = "http://www.baidu.com/s?wd={keyword}&pn={pagenum}".format( keyword=keyword, pagenum=page )
        r = requests.get( url )  # assums baidu works ok
        htmlpage = j_pentest_utils.bytes_to_unicode( r.content )
        soup = BeautifulSoup(htmlpage, 'lxml')
        for child in soup.findAll("h3", {"class": "t"}):
            try:
                link = child.a.get( 'href' )
                url = requests.get( link, allow_redirects=True, timeout=3 ).url
                urls.add( url )
            except:
                traceback.print_exc()
    return urls

if __name__=='__main__':
    print('do not call this directly')
